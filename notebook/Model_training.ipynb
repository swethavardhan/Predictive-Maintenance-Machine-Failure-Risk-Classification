{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9eecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c39b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899c2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding\n",
    "le = LabelEncoder()\n",
    "df['Type_encoded'] = le.fit_transform(df['Type'])  # L->0, M->1, H->2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81c0ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Type','Unnamed: 0','Failure Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5541cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting\n",
    "X = df.drop('Target', axis=1)  \n",
    "y = df['Target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a42143",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0855cc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    7729\n",
       "1     271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before handling imbalance\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16ad030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    7729\n",
       "1    7729\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SMOTE \n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "y_train_res.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe8dd5",
   "metadata": {},
   "source": [
    "Model Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef22e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91      1932\n",
      "           1       0.15      0.79      0.26        68\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.57      0.82      0.58      2000\n",
      "weighted avg       0.96      0.84      0.89      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1634  298]\n",
      " [  14   54]]\n",
      "ROC-AUC Score: 0.894782913165266\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight = 'balanced',\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "y_proba = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Logistic Regression Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd6026b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_res.columns = X_train_res.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace('[^A-Za-z0-9_]+', '_', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009c88eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swetha Pooduru\\Desktop\\Predictive Maintenance Machine Failure Risk Classification\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [22:31:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1932\n",
      "           1       0.56      0.81      0.66        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.78      0.89      0.82      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1889   43]\n",
      " [  13   55]]\n",
      "ROC-AUC Score: 0.9626720253318719\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "scale_pos_weight = (y_train_res==0).sum() / (y_train_res==1).sum()\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "xgb.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "y_proba = xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "print(\"=== XGBoost Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8edc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      1932\n",
      "           1       0.43      0.75      0.55        68\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.71      0.86      0.76      2000\n",
      "weighted avg       0.97      0.96      0.96      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1864   68]\n",
      " [  17   51]]\n",
      "ROC-AUC Score: 0.9619489099987821\n"
     ]
    }
   ],
   "source": [
    "#RansomForestClassfier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'  \n",
    ")\n",
    "\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Random Forest Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf39a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1932\n",
      "           1       0.31      0.85      0.45        68\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.65      0.89      0.71      2000\n",
      "weighted avg       0.97      0.93      0.95      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1803  129]\n",
      " [  10   58]]\n",
      "ROC-AUC: 0.9459528376568019\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=6,                \n",
    "    min_samples_leaf=20,        \n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "y_proba = dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Decision Tree Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4faeaea",
   "metadata": {},
   "source": [
    "individually they seems fine with average recall, so lets experiment with ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d4f5e",
   "metadata": {},
   "source": [
    "# ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc27b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swetha Pooduru\\Desktop\\Predictive Maintenance Machine Failure Risk Classification\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [22:41:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Soft Voting Ensemble Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1932\n",
      "           1       0.50      0.79      0.62        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.75      0.88      0.80      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1879   53]\n",
      " [  14   54]]\n",
      "ROC-AUC: 0.9683503836317136\n"
     ]
    }
   ],
   "source": [
    "# Xg + RF with softvoting\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "ensemble_soft = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "ensemble_soft.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = ensemble_soft.predict(X_test)\n",
    "y_proba = ensemble_soft.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Soft Voting Ensemble Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "904b687f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swetha Pooduru\\Desktop\\Predictive Maintenance Machine Failure Risk Classification\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [22:42:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Weighted Ensemble Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1932\n",
      "           1       0.52      0.81      0.63        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.76      0.89      0.81      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1881   51]\n",
      " [  13   55]]\n",
      "ROC-AUC: 0.9690354402630617\n"
     ]
    }
   ],
   "source": [
    "# Xg + RF with weighted classifier\n",
    "ensemble_weighted = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 2]  )\n",
    "\n",
    "ensemble_weighted.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = ensemble_weighted.predict(X_test)\n",
    "y_proba = ensemble_weighted.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Weighted Ensemble Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2447733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stacking Ensemble Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1932\n",
      "           1       0.54      0.76      0.63        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.76      0.87      0.81      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1887   45]\n",
      " [  16   52]]\n",
      "ROC-AUC: 0.9689136524174886\n"
     ]
    }
   ],
   "source": [
    "# XG + RF with stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(class_weight='balanced'),\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "y_proba = stacking_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Stacking Ensemble Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b456515",
   "metadata": {},
   "source": [
    "weighted classifying method gives better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be9d66c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swetha Pooduru\\Desktop\\Predictive Maintenance Machine Failure Risk Classification\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [22:44:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Ensemble (DT + RF + XGB) Metrics ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1932\n",
      "           1       0.51      0.81      0.62        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.75      0.89      0.80      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1879   53]\n",
      " [  13   55]]\n",
      "ROC-AUC: 0.9682971014492754\n"
     ]
    }
   ],
   "source": [
    "# XG + RF + DT with weighted voting\n",
    "ensemble_final = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dt', dt),\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[1, 2, 3]\n",
    ")\n",
    "\n",
    "ensemble_final.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred = ensemble_final.predict(X_test)\n",
    "y_proba = ensemble_final.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"=== Final Ensemble (DT + RF + XGB) Metrics ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d6fb5",
   "metadata": {},
   "source": [
    "3 models does not seem any better. Let's experiment with DT, RF, XG 2 at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0929d0",
   "metadata": {},
   "source": [
    "#experimenting with multiple thresholds on the weihted ensemble model (XG + RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f7e382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC (Final Model): 0.9690354402630617\n",
      "\n",
      "==================================================\n",
      "Threshold = 0.25\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      1932\n",
      "           1       0.43      0.84      0.56        68\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.71      0.90      0.77      2000\n",
      "weighted avg       0.97      0.96      0.96      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1855   77]\n",
      " [  11   57]]\n",
      "\n",
      "==================================================\n",
      "Threshold = 0.3\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      1932\n",
      "           1       0.45      0.84      0.59        68\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.72      0.90      0.78      2000\n",
      "weighted avg       0.98      0.96      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1863   69]\n",
      " [  11   57]]\n",
      "\n",
      "==================================================\n",
      "Threshold = 0.35\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1932\n",
      "           1       0.48      0.84      0.61        68\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.74      0.90      0.80      2000\n",
      "weighted avg       0.98      0.96      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1870   62]\n",
      " [  11   57]]\n",
      "\n",
      "==================================================\n",
      "Threshold = 0.4\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1932\n",
      "           1       0.49      0.81      0.61        68\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.74      0.89      0.80      2000\n",
      "weighted avg       0.98      0.96      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1875   57]\n",
      " [  13   55]]\n",
      "\n",
      "==================================================\n",
      "Threshold = 0.5\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1932\n",
      "           1       0.52      0.81      0.63        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.76      0.89      0.81      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1881   51]\n",
      " [  13   55]]\n"
     ]
    }
   ],
   "source": [
    "y_proba = ensemble_weighted.predict_proba(X_test)[:, 1]\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC (Final Model):\", roc_auc)\n",
    "\n",
    "#multiple thresholds\n",
    "thresholds = [0.25, 0.30, 0.35, 0.40, 0.50]\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_proba >= t).astype(int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Threshold = {t}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(classification_report(y_test, y_pred_t))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_t)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53289900",
   "metadata": {},
   "source": [
    "default is 0.5 taken and the performance seems a bit better at 0.35 . i'd like not to go lower than 0.35 tho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe925c",
   "metadata": {},
   "source": [
    "#XG + RF with ADASYN sampling at 0.5 nd 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73b7770d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADASYN, class counts: [7729 7671]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Swetha Pooduru\\Desktop\\Predictive Maintenance Machine Failure Risk Classification\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [22:54:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Weighted Ensemble with ADASYN, Threshold 0.5 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1932\n",
      "           1       0.52      0.81      0.64        68\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.76      0.89      0.81      2000\n",
      "weighted avg       0.98      0.97      0.97      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1882   50]\n",
      " [  13   55]]\n",
      "ROC-AUC: 0.9692409572524663\n",
      "\n",
      "=== Weighted Ensemble with ADASYN, Threshold 0.35 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      1932\n",
      "           1       0.43      0.82      0.57        68\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.71      0.89      0.77      2000\n",
      "weighted avg       0.97      0.96      0.96      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1858   74]\n",
      " [  12   56]]\n",
      "ROC-AUC: 0.9692409572524663\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "X_train.columns = X_train.columns.str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After ADASYN, class counts:\", np.bincount(y_train_res))\n",
    "# RF\n",
    "rf_best = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# XG\n",
    "scale_pos_weight = (y_train_res == 0).sum() / (y_train_res == 1).sum()\n",
    "xgb_best = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#Ensemble\n",
    "ensemble_best = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_best),\n",
    "        ('xgb', xgb_best)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[2, 3]\n",
    ")\n",
    "\n",
    "\n",
    "ensemble_best.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_proba = ensemble_best.predict_proba(X_test)[:, 1]\n",
    "#0.5\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "print(\"\\n=== Weighted Ensemble with ADASYN, Threshold 0.5 ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "#0.35\n",
    "threshold = 0.35\n",
    "y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== Weighted Ensemble with ADASYN, Threshold 0.35 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1ad08",
   "metadata": {},
   "source": [
    "#let's try XG + DT with SMOTE and ADASYn at 0.5 nd 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bb09caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DT+XGB Ensemble, Threshold 0.5 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      1932\n",
      "           1       0.34      0.85      0.48        68\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.66      0.90      0.72      2000\n",
      "weighted avg       0.97      0.94      0.95      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1817  115]\n",
      " [  10   58]]\n",
      "ROC-AUC: 0.9359624284496407\n",
      "\n",
      "=== DT+XGB Ensemble, Threshold 0.35 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      1932\n",
      "           1       0.26      0.88      0.41        68\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.63      0.90      0.68      2000\n",
      "weighted avg       0.97      0.91      0.93      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1764  168]\n",
      " [   8   60]]\n",
      "ROC-AUC: 0.9359624284496407\n"
     ]
    }
   ],
   "source": [
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=5,  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scale_pos_weight = (y_train_res == 0).sum() / (y_train_res == 1).sum()\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "ensemble_dt_xgb = VotingClassifier(\n",
    "    estimators=[('dt', dt), ('xgb', xgb)],\n",
    "    voting='soft',\n",
    "    weights=[3, 2]\n",
    ")\n",
    "\n",
    "ensemble_dt_xgb.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_proba = ensemble_dt_xgb.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "print(\"=== DT+XGB Ensemble, Threshold 0.5 ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "\n",
    "threshold = 0.35\n",
    "y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+XGB Ensemble, Threshold 0.35 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68ceb16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE, class counts: [7729 7729]\n",
      "\n",
      "=== DT+XGB Ensemble with SMOTE, Threshold 0.5 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      1932\n",
      "           1       0.37      0.85      0.52        68\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.68      0.90      0.74      2000\n",
      "weighted avg       0.97      0.95      0.96      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1833   99]\n",
      " [  10   58]]\n",
      "ROC-AUC: 0.9550222262818171\n",
      "\n",
      "=== DT+XGB Ensemble with SMOTE, Threshold 0.35 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96      1932\n",
      "           1       0.29      0.88      0.43        68\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.64      0.90      0.69      2000\n",
      "weighted avg       0.97      0.92      0.94      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1782  150]\n",
      " [   8   60]]\n",
      "ROC-AUC: 0.9550222262818171\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "X_train.columns = X_train.columns.str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE, class counts:\", np.bincount(y_train_res))\n",
    "\n",
    "#DT\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# XG\n",
    "scale_pos_weight = (y_train_res == 0).sum() / (y_train_res == 1).sum()\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "ensemble_dt_xgb = VotingClassifier(\n",
    "    estimators=[('dt', dt), ('xgb', xgb)],\n",
    "    voting='soft',\n",
    "    weights=[3, 2]\n",
    ")\n",
    "\n",
    "\n",
    "ensemble_dt_xgb.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_proba = ensemble_dt_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "print(\"\\n=== DT+XGB Ensemble with SMOTE, Threshold 0.5 ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "\n",
    "threshold = 0.35\n",
    "y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+XGB Ensemble with SMOTE, Threshold 0.35 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4df40a",
   "metadata": {},
   "source": [
    "#let's try RF + DT with SMOTE and ADASYN at 0.5 and 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f80f8251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE, class counts: [7729 7729]\n",
      "\n",
      "=== DT+RF Ensemble with SMOTE, Threshold 0.5 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      1932\n",
      "           1       0.30      0.85      0.44        68\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.65      0.89      0.70      2000\n",
      "weighted avg       0.97      0.93      0.94      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1797  135]\n",
      " [  10   58]]\n",
      "ROC-AUC: 0.9563352514919011\n",
      "\n",
      "=== DT+RF Ensemble with SMOTE, Threshold 0.35 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96      1932\n",
      "           1       0.28      0.88      0.43        68\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.64      0.90      0.69      2000\n",
      "weighted avg       0.97      0.92      0.94      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1778  154]\n",
      " [   8   60]]\n",
      "ROC-AUC: 0.9563352514919011\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "X_train.columns = X_train.columns.str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"After SMOTE, class counts:\", np.bincount(y_train_res))\n",
    "\n",
    "#DT\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "#RF\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "ensemble_dt_rf = VotingClassifier(\n",
    "    estimators=[('dt', dt), ('rf', rf)],\n",
    "    voting='soft',\n",
    "    weights=[3, 2]\n",
    ")\n",
    "\n",
    "ensemble_dt_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_proba = ensemble_dt_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with SMOTE, Threshold 0.5 ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "threshold = 0.35\n",
    "y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with SMOTE, Threshold 0.35 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19055c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADASYN, class counts: [7729 7671]\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.5 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1932\n",
      "           1       0.27      0.87      0.41        68\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.63      0.89      0.68      2000\n",
      "weighted avg       0.97      0.92      0.94      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1773  159]\n",
      " [   9   59]]\n",
      "ROC-AUC: 0.957770064547558\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.35 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1932\n",
      "           1       0.26      0.87      0.40        68\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.63      0.89      0.68      2000\n",
      "weighted avg       0.97      0.91      0.93      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1764  168]\n",
      " [   9   59]]\n",
      "ROC-AUC: 0.957770064547558\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.3 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1932\n",
      "           1       0.26      0.87      0.40        68\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.63      0.89      0.67      2000\n",
      "weighted avg       0.97      0.91      0.93      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1761  171]\n",
      " [   9   59]]\n",
      "ROC-AUC: 0.957770064547558\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.columns = X_train.columns.astype(str).str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "X_test.columns = X_test.columns.astype(str).str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "print(\"After ADASYN, class counts:\", np.bincount(y_train_res))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5,  random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200,  random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('dt', dt), ('rf', rf)],\n",
    "    voting='soft',\n",
    "    weights=[4, 2]  )\n",
    "\n",
    "ensemble.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_proba = ensemble.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.5 ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "\n",
    "threshold = 0.35\n",
    "y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.35 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred_thresh2 = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.3 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh2))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh2))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f7a667",
   "metadata": {},
   "source": [
    "#getting better. Let's try playing with model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "614aa5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADASYN, class counts: [7729 7671]\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.5 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1932\n",
      "           1       0.27      0.87      0.41        68\n",
      "\n",
      "    accuracy                           0.92      2000\n",
      "   macro avg       0.63      0.89      0.68      2000\n",
      "weighted avg       0.97      0.92      0.94      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1771  161]\n",
      " [   9   59]]\n",
      "ROC-AUC: 0.9560269760077944\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.35 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1932\n",
      "           1       0.26      0.87      0.40        68\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.63      0.89      0.68      2000\n",
      "weighted avg       0.97      0.91      0.93      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1764  168]\n",
      " [   9   59]]\n",
      "ROC-AUC: 0.9560269760077944\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.3 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      1932\n",
      "           1       0.26      0.87      0.40        68\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.63      0.89      0.67      2000\n",
      "weighted avg       0.97      0.91      0.93      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1761  171]\n",
      " [   9   59]]\n",
      "ROC-AUC: 0.9560269760077944\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.columns = X_train.columns.astype(str).str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "X_test.columns = X_test.columns.astype(str).str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "print(\"After ADASYN, class counts:\", np.bincount(y_train_res))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('dt', dt), ('rf', rf)],\n",
    "    voting='soft',\n",
    "    weights=[5, 2]  \n",
    ")\n",
    "ensemble.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "y_proba = ensemble.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.5 ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "threshold = 0.35\n",
    "y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.35 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred_thresh2 = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.3 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh2))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh2))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6aa92ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#almost the same , let's do class weights too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b74778e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After ADASYN, class counts: [7729 7671]\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.5 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91      1932\n",
      "           1       0.17      0.93      0.29        68\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.58      0.88      0.60      2000\n",
      "weighted avg       0.97      0.85      0.89      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1629  303]\n",
      " [   5   63]]\n",
      "ROC-AUC: 0.9436502862014372\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.35 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86      1932\n",
      "           1       0.12      0.93      0.21        68\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.56      0.84      0.54      2000\n",
      "weighted avg       0.97      0.76      0.84      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1463  469]\n",
      " [   5   63]]\n",
      "ROC-AUC: 0.9436502862014372\n",
      "\n",
      "=== DT+RF Ensemble with ADASYN, Threshold 0.3 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84      1932\n",
      "           1       0.11      0.96      0.20        68\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.55      0.84      0.52      2000\n",
      "weighted avg       0.97      0.73      0.82      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1400  532]\n",
      " [   3   65]]\n",
      "ROC-AUC: 0.9436502862014372\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "X_train.columns = X_train.columns.astype(str).str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "X_test.columns = X_test.columns.astype(str).str.replace('[\\\\[\\\\]<]', '', regex=True)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_res, y_train_res = adasyn.fit_resample(X_train, y_train)\n",
    "print(\"After ADASYN, class counts:\", np.bincount(y_train_res))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5, class_weight={0:1, 1:10}, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, class_weight={0:1, 1:10}, random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('dt', dt), ('rf', rf)],\n",
    "    voting='soft',\n",
    "    weights=[5, 2]  \n",
    ")\n",
    "ensemble.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_proba = ensemble.predict_proba(X_test)[:,1]\n",
    "\n",
    "y_pred_default = (y_proba >= 0.5).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.5 ===\")\n",
    "print(classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "\n",
    "threshold = 0.35\n",
    "y_pred_thresh = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.35 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
    "\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred_thresh2 = (y_proba >= threshold).astype(int)\n",
    "print(\"\\n=== DT+RF Ensemble with ADASYN, Threshold 0.3 ===\")\n",
    "print(classification_report(y_test, y_pred_thresh2))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_thresh2))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2234c",
   "metadata": {},
   "source": [
    "This is much better. Recall 0.93 at 0.5, 0.93 at 0.35, 0.96 at 0.3 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e3b643a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ensemble_thresh_0.3.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "saved_models = {\n",
    "    'ensemble_model': ensemble,  \n",
    "    'thresholds': {\n",
    "        '0.5': 0.5,\n",
    "        '0.35': 0.35,\n",
    "        '0.3': 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump({'model': ensemble, 'threshold': 0.5}, 'ensemble_thresh_0.5.pkl')\n",
    "joblib.dump({'model': ensemble, 'threshold': 0.35}, 'ensemble_thresh_0.35.pkl')\n",
    "joblib.dump({'model': ensemble, 'threshold': 0.3}, 'ensemble_thresh_0.3.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa1c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
